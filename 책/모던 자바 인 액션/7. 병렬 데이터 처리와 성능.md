# 7. 병렬 데이터 처리와 성능

### 자바의 병렬 처리

1. 자바7 등장 이전 데이터 컬렉션을 병렬 처리 하기 어려웠다. 
    
    우선 데이터를 서브 파트로 분리하고, 분할된 서브파트를 각각 스레드로 할당한다. 의도치않은 race condition이 발생하지 않도록 동기화를 추가하고 최종적으로 부분 결과를 합쳐야한다.
    
2. 자바7은 더 쉽게 병렬화를 수행하며 에러를 최소화할 수 있도록 **포크/조인 프레임워크** 기능을 제공한다.
3. 스트림을 이용하면 순차 스트림으로 자연스럽게 바꿀 수 있다.

# 병렬 스트림

스트림 인터페이스를 이용하면 간단하게 요소를 병렬로 처리할 수 있다. 컬렉션에 `parallelStream`을 호출하면 병렬 스트림이 생성된다. 

각각의 스레드에서 처리할 수 있도록 스트림 요소를 여러 청크로 분할하며, 모든 멀티코어 프로세서가 각각 청크를 처리하도록 할당할 수 있다. 

```java
stream.parallel()
			.filter(...)
			.sequential() // parallel와 반대로 병렬 스트림을 순차 스트림으로 변경할 때 사용한다.
			.map(...); 

// -> 두 메소드 중 최종적으로 호출된 메서드가 전체 파이프 라인에 영향을 미친다.
```

### 병렬 스트림의 스레드풀

: 병렬 스트림은 내부적으로 ForkJoinPool을 사용한다. (포크/ 조인 프레임워크)

: 기본적으로 ForkJoinPool은 프로세서 수 (`Runtime.getRuntime().availavleProcessors()`의 반환값)에 상응하는 스레드량을 가진다.

: 커스터마이즈할 수 있으나 전역 설정 코드이므로, 모든 병렬 스트림 연산에 영향을 준다. 일반적으로 기기의 프로세서 수와 같으므로 특별한 이유가 없다면 ForkJoinPool의 기본값을 그대로 사용하는 것을 권장한다.

```java
System.setProperty("java.util.concurrent.ForkOoinPool.common.parallelism", "12");
```

### 성능 측정 라이브러리

- 자바 마이크로벤치마크 하니스 (JVH)

JVM을 대상으로 벤치마크가 쉽지 않은 이유

→ 핫스팟이 바이트코드를 최적화하는데 필요한 시간 (웜업)

→ 가비지 컬렉터로 인한 오버헤드

→ 대상 결과값을 죽은 코드로 판단할 수 있다

### 성능 측정 결과

```java
Stream.iterate(1L, i -> i + 1)
			.limit(N)
			.reduce(0L, Long::sum);
```

1. **전통적인 for 루프를 사용 반복** 
    
    →  더 저수준으로 동작하며, 기본값을 박싱하거나 언박싱할 필요가 없어 가장 빠르다.
    
2. **순차 스트림**
    
    → 이때, `LongStream.rangeClosed`을 사용하려 박싱 오버헤드를 줄이면 전통적은 for문과 근사한 성능을 얻을 수 있다.  (상황에 따라 알고리즘 보다 적절한 자료구조를 선택하는 것이 중요하다는 것을 알 수 있다.)
    
3. **병렬 스트림**
    
    → 병렬 버전이 멀티 코어 CPU를 활용하지 못하였다.
    
    → 반복 작업은 병렬로 수행할 수 있는 독립 단위로 나누기 어렵다.
    
    → 이전 연산의 결과에 따라 다음 입력이 달라진는 iterate 연산을 청크로 분할하기는 어렵다. (iterate는 본질적으로 순차적이다. ) 리듀싱 과정을 시작하는 시점에 전체 숫자 리스트가 준비되지 않아 정크로 분할할 수 없다.
    
    → 병렬로 처리되도록 지시하였기 때문에 각각의 합계가 다른 스레드에서 수행되었지만 순차처리 방식 + 스레드를 할당하는 오버헤드로 인해 성능이 더 안좋은 것을 확인할 수 있다.
    
    → 병렬 특화 메소드로 변경 (순차 실행보다 빠른 처리 속도를 얻을 수 있다.)
    
    ```java
    LongStream.rangeClosed(0,N)
    					.parallel()
    					.reduce(0L, Long::sum);
    // 1. 기본형이기 때문에 오토박싱에 대한 오버헤드가 줄어든다. 
    // 2. 쉽게 청크로 분할할 수 있는 숫자 범위를 생성한다.
    ```
    
    올바른 자료구조를 선택해야만 병렬 실행도 성능을 발휘할 수 있다.
    

### 병렬 스트림의 올바른 사용

병렬화는 비용이 든다. 

1. 스트림을 재귀적으로 분할해야한다.
2. 각 서브스트림을 서로 다른 스레드의 리듀싱 연산에 할당해야한다. 
3. 해당 결과들을 하나로 합쳐야한다. 

→ 멀티 코어간의 데이터 이동은 우리 생각보다 비싸다. 따라서 코어 간에 데이터 번송 시간보다 훨씬 오래 걸리는 작업만 병렬로 수행하는 것이 바람직하다.

- **공유된 가변 상태는 피해야한다.**
    
    : 다수의 스레드가 공유자원에 접근할 경우 race가 발생하며 동기화 문제로 해결하다보면 결국 병렬화 특성을 잃는다. 
    
    : 원자값 연산이 아니라면 정답 또한 보장할 수 없다.
    
- **병렬 스트림이 효과적인 수량을 측징해라**
    
    : 벤치마크를 통해 직접 성능을 측정해라.
    
- **박싱을 주의하라**
    
    : 기본형 특화 스트림을 사용해라
    
- **병렬 처리시  성능이 떨어지는 연산을 주의해라.**
    
    : limit이나 findFirst 같이 요소의 순서에 의존하는 연산은 병렬 처리 성능을 떨어트린다.
    
    →  순서가 상관없다면 *비정렬된 스트림에 limit, findFirst보다는 findAny를* 사용하는 것이 더 효율적이다.
    
- **전체 파이프 라인의 연산 비용을 계산해라.**
    
    : `처리해야할 연산 수 X 요소를 처리하는데 드는 비용` 비용이 클수록 병렬 스트림을 통해 성능  개선될 가능성이 크다.
    
    : 소량의 데이터에서 병렬 스트림은 도움이 되지않는다. 병렬화를 하는데 생기는 부가 비용이 더 클것이기 때문.
    
- **분할을 위한 적절한 자료구조 스트림인지 확인해라**
    
    
    | 자료구조 | 분해성 |
    | --- | --- |
    | ArrayList | 매우 좋음 |
    | LinkedList | 나쁨 → 분할시 요소를 전체 탐색해야함 |
    | IntStream.range | 매우 좋음 (팩토리 메소드로 만든 기본형 스트림) |
    | Stream.iterate | 나쁨 |
    | HashSet | 좋음 |
    | TreeSet | 좋음 |
- **병합과정의 비용을 살펴봐야한다.**
    
    : 병합 비용이 비싸다면 병렬처리 이점이 상세된다.
    

# 포크/ 조인 프레임워크

병렬화할 수 있는 작업을 재귀적으로 작은 작업으로 분할한 다음에 서브태스크 각각의 결과를 합쳐서 전체 결과를 만들도록 설계되었다. 

서브태스크를 스레드 풀(ForkJoinPool)의 작업자 스레드에 분산 할당하여 ExecutorService 인터페이스를 구현한다.

### RecursiveTask

스레드 풀을 이용하려면 `RecuriveTask<R>`의 서브클래스를 만들어야한다. 

추상 메소드인 `compute` 메소드는 테스크를 서브태스크로 분할하는 로직과 더 이상 분할할 수 없을 때 개별 서브태스크의 결과를 생산할 알고리즘을 정한다.

```
if (태스크가 충분히 작거나 분할할 수 없다){
	순차적으로 테스트 계산
} else {
	태스크를 두 서브태스크로 분할.
	재귀적으로 해당 메서드를 호출하여 각 서브태스크의 결과를 함침
}
```

분할 후 정복 알고리즘의 병렬화 버전이다. 

**활용**

```java
public class ForkJoinSumCalculator extend RecursiveTask<Long> {
		public static final long THRESHOLD = 10_000; //이 값 이하의 서브테스크는 더이상 분할하지 않는다. 
		
		private final long[] numbers;
		private final int start;
		private final int end;

		// 메인 테스크를 생성할 떄 사용할 공개 생성자
		public ForkJoinSumCalculator (long[] numbers){
				this(numbers, 0, numbers.length);
		}

		// 서브태스크를 재귀적으로 만들때 사용할 비공개 생성자
		private ForkJoinSumCalculator (long[] numbers, int start, int end){
				this.number = number;
				this.start = start;
				this.end = end;
		}
		
		@Override
		protected Long compute(){
					if (end-start <= THRESHOLD) { // 재귀가 멈추는 지점
							// 순차적 계산 수행
					} else {
							ForkJoinSumCalculator leftTask = new ForkJoinSumCalculator(numbers, start, end/2);
							leftTask.fork(); 
							ForkJoinSumCalculator rightTask = new ForkJoinSumCalculator(numbers, end/2, end);
							return rightTask.compute() + left.join(); 
							// 두번째 테스크는 동기 실행하여 첫번째 테스크의 값과 합한다. 
					}
		}
}
```

호출

```java
public static long forkJoinSum(long n){
		long[] numbers = LongStream.range(1,n).toArray();
		ForkJoinTask<Long> task = new ForJoinSumCalculate(numbers);
		return new ForkJoinPool().invoke(task); // task에서 정의된 결과를 반환한다. 
}
```

일반적으로 애플리케이션에서는 ForkJoinPool을 한번만 인스턴스화해 정적 필드 싱글턴으로 저장한다. 

인수가 없는 디폴트 생성자를 이용하면 `Runtime.availableProcessors`의 반환값으로 스레드 수를 결정한다.

### 포크/조인 프레임워크 제대로 사용하기

- Join 메서드를 호출하면 테스크가 생성한 결과가 준비될 때까지 호출자를 블록시킨다. 따라서 두 서브태스크가 모두 시작된 다음에 `join`을 호출해야한다.
- RecursiveTask 내에서는 ForkJoinPool의 `invoke` 메소드를 사용하지  말아야한다. 순차 코드에서 병렬 계산을 시작할때만 invoke를 사용하고 대신 `compute`나 `fork` 메소드를 직접 호출한다.
- fork메소드를 직접 호출해 ForkJoinPool의 일정을 조율할 수 있다. 이때 불필요한 태스크를 할당하는 오버헤드를 피해라. (leftTask만 병렬 할당 해준 이유)
- 병렬 계산은 디버깅이 어렵다. 순차처리는 IDE로 디버깅할때 스택 트레이스로 문제가 일어난 과정을 파악하기 쉽지만 다른 스레드에서 compute을 호출할 경우 스택 트레이스는 도움이 되지 않는다.
- 서브태스크의 실행시간이 새로운 태스크를 포킹하는 데 드는 시간보다 길어야 순차처리보다 빠른 결과를 얻을 수 있다. (꼭 병렬처리가 빠를 거라는 생각은 버려라.)

### 분할 기준

예제에서는 덧셈을  수행할 숫자가 만개 이하면 분할을 중단했다. 기분 값을 바꿔가며 최적화된 기준을 찾는 것 외에 좋은 기준을 찾는 뽀족한 방법은 없다. 

코어가 4개뿐인 기기에 천 개 이상의 서브태스크를 분할하는 것은 자원을 낭비하는 것 같지만 실제로 코어 개수와 관계없이 적절한 크기로 분할된 많은 테스크를 포킹하는 것이 바람직하다. 

→ 이론적으로는 크기가 같은 각각의 태스크가 코어에서 같은 시간에 종료할 것이라 생각들지만 복잡한 시나리오가 사용되는 현실에서는 각각의 작업시간이 크게 달라질 수 있다. 

→ 포크/조인 프레임워크는 **작업 훔치기** 기법으로 이 문제를 해결한다. 

: 작업 훔치기 기법은 ForkJoinPool의 모든 스레드를 거의 공정하게 분할한다. 

: 각각의 스레드는 작업이 끝날 때마다 *큐의 헤드*에서 작업을 가져와 처리한다. 이때 할일은 먼저 마친 스레드는 유휴 상태로 바뀌는 것이 아니라 다른 스레드 *큐의 꼬리*에서 작업을 훔쳐온다.

: 모든 큐가 빌 때까지 이 과정을 반복하여 스레드 간의 작업부화를 비슷한 수준으로 유지할 수 있다.

# Spliterator 인터페이스

스트림에는 자동으로 분할해주는 기법인 Spliterator가 있다. ‘분할할 수 있는 반복자’라는 의미이다. 

---

[쓰레드풀과 ForkJoinPool](https://hamait.tistory.com/m/612)

[stream과 for-loop의 속도 차이](https://sigridjin.medium.com/java-stream-api%EB%8A%94-%EC%99%9C-for-loop%EB%B3%B4%EB%8B%A4-%EB%8A%90%EB%A6%B4%EA%B9%8C-50dec4b9974b)
