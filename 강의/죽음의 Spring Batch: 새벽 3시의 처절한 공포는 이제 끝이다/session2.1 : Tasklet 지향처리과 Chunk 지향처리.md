# Session 2-1

## Tasklet 지향 처리
ETL 작업이 아닌 단순한 시스템 작업이나 유틸성 작업
- 주기적 로그 파일 삭제
- 특정 디렉토리 오래된 파일 아카이브
- 사용자에게 알람 또는 이메일 발송
- 외부 API호출 후 결과 저장

### RepestStatus : FINISHED vs CONTINUABLE
- `RepeatStatus.FINISHED` : Step의 처리가 성공이든 실패든 상관없이 해당 Step이 완료되었음을 의미
- `RepeatStatus.CONTINUABLE` : Tasklet의 `execute()`메서드가 추가로 더 실행되어야 함을 Spring Batch Step에 알리는 신호. Step 종료는 보류되고, 필요한 만큼 `execute()`를 반복 실행한다.


RepestStatus는 반복문 이상의 제어 구조. Spring Batch는 Tasklet의 execute() 호출 마다 새로운 트랜잭션을 시작하기때문에 RepeatStatus가 반환되면 해당 트랜잭션을 커밋한다.

파일을 정리하거나, 외부 API를 호출하거나, 단순한 알림을 보내는 작업 등 트랜잭션이 필요없는 tasklet에서 실제 DB 커넥션을 관리하는 `PlatformTransactionManager` 구현체 대신 `ResourcelessTransactionManager`를 사용한다.
`ResourcelessTransactionManager`는 bean이 아니기때문에 별도의 bean을 정의하거나 new 인스턴스를 생성해서 사용할 수 있다.

</br>

## Chunk 지향 처리
대부분의 배치 작업, 특히 데이터를 **읽기 -> 처리 -> 쓰기**라는 공통된 패턴으로 다룰 때 사용하는 방식

### Chunk란?
데이터를 일정 단위로 쪼갠 덩어리. 
읽고, 처리하고, 쓰는 작업을 일정 크기로 나눈 데이터(청크)를 대상으로 처리하는 것이 청크 지향 처리

### Chunk를 사용하는 이유 
Batch는 수백만/수천만 건의 데이터를 다루는 작업이 보통일 정도로 데이터의 양이 방대하다. 이러한 데이터를 한 번에 메모리로 불러오고, 처리하고, 저장한다면 시스템이 폭팔할 것!
- 메모리가 터진다.
- DB 과부하가 걸린다.

또한 Chunk단위로 나눠 처리하면 트랜잭션 분리가 가능. 에러가 발생하더라도 작업의 실패를 작은 실패로 제한하여 쉽고 빠르게 복구가 가능하다.

### ItemReader, ItemProcessor, ItemWriter

- ItemReader : 청크 지향 저리에서 데이터를 읽어오는 인터페이스
	- read() 메서드는 아이템을 하나씩 반환
	- 읽을 데이터가 더 이상 없으면 null을 반환하며, 스텝은 종료 (**청크 지향 처리 Step의 종료 시점**)
	- 다양한 구현체 제공


- ItemProcessor : 데이터를 원하는 형태로 깎아내는 가공하는 인터페이스
	- ItemReader가 넘긴 입력 데이터(I)를 원하는 형태(O)로 변환
	- process() 메서드가 null을 반환하면 해당 입력 데이터는 처리 흐름에서 제외된다. (유효하지 않은 데이터나 처리할 필요가 없는 데이터를 걸러낼 때 사용)
	- 입력 데이터의 유효성을 검사 작업을 진행하여 예외를 던져 잡을 중단시킬 수 있다.


- ItemWriter : 결과물을 받아, 원하는 방식으로 최종 저장/출력하는 인터페이스
	- 데이터를 DB에 `INSERT`, 파일에 `WRITE`, 메시지 큐에 `PUSH`둥
	- **Chunk 단위로 묶어서 한 번에 데이터를 쓴다**
	- 다양한 구현체 제공

</br>

> 해당 패턴의 장점
> 1. 완벽한 책임 분리 : 각 컴포넌트는 자신의 역할만 수행. 명확한 코드와 간단한 유지보수
> 2. 재사용성 극대화 : 컴포넌트들은 독립적으로 설계되어 있어 어디서든 재사용 가능
> 3. 높은 유연성 : 요구사항이 변경되어도 해당 컴포넌트만 수정하면 된다
> 4. 대용량 처리의 표준 : 데이터를 다루는 작업은 결국 '읽고-처리하고-쓰는' 패턴을 따른다.

</br>

### 청크 지향 처리의 흐름
청크 지향 처리는 읽기-깎기-쓰기를 청크 크기 단위로 묶어서 반복한다.

1. 데이터 읽기 
	- 데이터 소스에서 하나씩 데이터를 읽어온다. `read()` 메서드가 호출될 때마다 데이터를 순차적으로 반환
	- 청크 크기만큼 데이터를 읽어야 끝난다 (청크 크기가 10이면 `read()`가 10번 호출되어 하나의 청크가 생성)
2. 데이터 깍기
	- 청크의 각 아이템 하나씩을 처리
	- 청크의 아이템마다 process()를 반복 호출해서 데이터를 변환하거나 필터링
3. 데이터 쓰기
	- ItemReader/ItemProcessor가 각각의 아이템을 하나씩 처리하는 것과 달리, ItemWriter는 청크 전체를 한 번에 입력을 받아 청크 단위로 저장

*청크 크기만큼 ItemReader.read()가 모두 호출된 후에 그 다음 청크 크기만큼 ItemProcessor.process()가 호출된다는 사실 주의!!*
> 하나의 chunk : `read()` 10번 호출 (chunk 생성) -> `process()` 10번 호출 -> `write()` 호출

</br>

### ‘청크 단위 반복’의 종료 조건
*더 이상 읽을 데이터가 없을 때* 모든 데이터를 처리했다고 인지. 즉, ItemReader의 read() 메서드가 null을 반환할 때

### 적절한 청크 사이즈란?
답이 없다. 다음의 두 가지 트레이드오프와 비즈니스 요구사항, 그리고 처리할 데이터의 양을 고려해서 적절히 선택해야 한다.

- **청크 사이즈가 클 때**
	- 많은 데이터를 한 번에 로드
	- 트랜잭션의 경계가 커지므로 롤백되는 데이터 양 증가
- **청크 사이즈가 작을 때**
	- 오류 발생시 롤백 데이터 최소화
	- 대신 그만큼 읽기/쓰기 I/O가 자주 발생

